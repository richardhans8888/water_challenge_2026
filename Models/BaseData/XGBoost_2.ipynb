{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46931c2a-a683-491d-b847-3f7ace2b5532",
   "metadata": {},
   "source": [
    "# XG Boost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea797ae-0dce-4b9d-8b29-3b635c364139",
   "metadata": {},
   "source": [
    "# (1) Load + merge ALL training datasets (Water Quality + TerraClimate + Landsat)\n",
    "\n",
    "- This cell:\n",
    "- loads the 3 training CSVs\n",
    "- creates stable merge keys (rounding lat/lon + normalized date)\n",
    "- merges features onto the water quality targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c916c9cd-75ba-467f-97ea-f64dbc528d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files:\n",
      "WQ: water_quality_training_dataset.csv\n",
      "TC: terraclimate_features_training.csv\n",
      "LS: landsat_features_training.csv\n",
      "Merged train_df shape: (19278121, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "      <th>lat_k</th>\n",
       "      <th>lon_k</th>\n",
       "      <th>date_k</th>\n",
       "      <th>Latitude_tc</th>\n",
       "      <th>...</th>\n",
       "      <th>pet</th>\n",
       "      <th>Latitude_ls</th>\n",
       "      <th>Longitude_ls</th>\n",
       "      <th>Sample Date_ls</th>\n",
       "      <th>nir</th>\n",
       "      <th>green</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>128.912</td>\n",
       "      <td>555.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-28.76083</td>\n",
       "      <td>17.73028</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>-28.760833</td>\n",
       "      <td>...</td>\n",
       "      <td>174.2</td>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11190.0</td>\n",
       "      <td>11426.0</td>\n",
       "      <td>7687.5</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>0.185538</td>\n",
       "      <td>0.195595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>74.720</td>\n",
       "      <td>162.9</td>\n",
       "      <td>163.0</td>\n",
       "      <td>-26.86111</td>\n",
       "      <td>28.88472</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>-26.861111</td>\n",
       "      <td>...</td>\n",
       "      <td>124.1</td>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>17658.5</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>13746.5</td>\n",
       "      <td>10574.0</td>\n",
       "      <td>0.124566</td>\n",
       "      <td>-0.180134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>89.254</td>\n",
       "      <td>573.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-26.45000</td>\n",
       "      <td>28.08583</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>-26.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>127.5</td>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>15210.0</td>\n",
       "      <td>10720.0</td>\n",
       "      <td>17974.0</td>\n",
       "      <td>14201.0</td>\n",
       "      <td>-0.083293</td>\n",
       "      <td>-0.252805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>82.000</td>\n",
       "      <td>203.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-27.67111</td>\n",
       "      <td>27.23694</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>-27.671111</td>\n",
       "      <td>...</td>\n",
       "      <td>129.7</td>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>14887.0</td>\n",
       "      <td>10943.0</td>\n",
       "      <td>13522.0</td>\n",
       "      <td>11403.0</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>-0.105416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>56.100</td>\n",
       "      <td>145.1</td>\n",
       "      <td>151.0</td>\n",
       "      <td>-27.35667</td>\n",
       "      <td>27.28639</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>-27.356667</td>\n",
       "      <td>...</td>\n",
       "      <td>129.2</td>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>16828.5</td>\n",
       "      <td>9502.5</td>\n",
       "      <td>12665.5</td>\n",
       "      <td>9643.0</td>\n",
       "      <td>0.141147</td>\n",
       "      <td>-0.142683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0 -28.760833  17.730278  2011-02-01           128.912                   555.0   \n",
       "1 -26.861111  28.884722  2011-03-01            74.720                   162.9   \n",
       "2 -26.450000  28.085833  2011-03-01            89.254                   573.0   \n",
       "3 -27.671111  27.236944  2011-03-01            82.000                   203.6   \n",
       "4 -27.356667  27.286389  2011-03-01            56.100                   145.1   \n",
       "\n",
       "   Dissolved Reactive Phosphorus     lat_k     lon_k      date_k  Latitude_tc  \\\n",
       "0                           10.0 -28.76083  17.73028  2011-02-01   -28.760833   \n",
       "1                          163.0 -26.86111  28.88472  2011-03-01   -26.861111   \n",
       "2                           80.0 -26.45000  28.08583  2011-03-01   -26.450000   \n",
       "3                          101.0 -27.67111  27.23694  2011-03-01   -27.671111   \n",
       "4                          151.0 -27.35667  27.28639  2011-03-01   -27.356667   \n",
       "\n",
       "   ...    pet Latitude_ls  Longitude_ls  Sample Date_ls      nir    green  \\\n",
       "0  ...  174.2  -28.760833     17.730278      2011-02-01  11190.0  11426.0   \n",
       "1  ...  124.1  -26.861111     28.884722      2011-03-01  17658.5   9550.0   \n",
       "2  ...  127.5  -26.450000     28.085833      2011-03-01  15210.0  10720.0   \n",
       "3  ...  129.7  -27.671111     27.236944      2011-03-01  14887.0  10943.0   \n",
       "4  ...  129.2  -27.356667     27.286389      2011-03-01  16828.5   9502.5   \n",
       "\n",
       "    swir16   swir22      NDMI     MNDWI  \n",
       "0   7687.5   7645.0  0.185538  0.195595  \n",
       "1  13746.5  10574.0  0.124566 -0.180134  \n",
       "2  17974.0  14201.0 -0.083293 -0.252805  \n",
       "3  13522.0  11403.0  0.048048 -0.105416  \n",
       "4  12665.5   9643.0  0.141147 -0.142683  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE_DIR = \"./\" \n",
    "\n",
    "WQ_TRAIN_PATH = os.path.join(BASE_DIR, \"water_quality_training_dataset.csv\")\n",
    "TC_TRAIN_PATH = os.path.join(BASE_DIR, \"terraclimate_features_training.csv\")\n",
    "LS_TRAIN_PATH = os.path.join(BASE_DIR, \"landsat_features_training.csv\")\n",
    "\n",
    "def _prep_keys(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if \"Sample Date\" in df.columns:\n",
    "        dt = pd.to_datetime(df[\"Sample Date\"], errors=\"coerce\")\n",
    "    elif \"Sample_Date\" in df.columns:\n",
    "        dt = pd.to_datetime(df[\"Sample_Date\"], errors=\"coerce\")\n",
    "        df[\"Sample Date\"] = df[\"Sample_Date\"]\n",
    "    else:\n",
    "        raise ValueError(\"Could not find 'Sample Date' column.\")\n",
    "    df[\"Sample Date\"] = dt.dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    df[\"Latitude\"]  = pd.to_numeric(df[\"Latitude\"], errors=\"coerce\")\n",
    "    df[\"Longitude\"] = pd.to_numeric(df[\"Longitude\"], errors=\"coerce\")\n",
    "\n",
    "    df[\"lat_k\"] = df[\"Latitude\"].round(5)\n",
    "    df[\"lon_k\"] = df[\"Longitude\"].round(5)\n",
    "    df[\"date_k\"] = df[\"Sample Date\"]\n",
    "    return df\n",
    "\n",
    "wq_train = _prep_keys(pd.read_csv(WQ_TRAIN_PATH))\n",
    "tc_train = _prep_keys(pd.read_csv(TC_TRAIN_PATH))\n",
    "ls_train = _prep_keys(pd.read_csv(LS_TRAIN_PATH))\n",
    "\n",
    "merge_keys = [\"lat_k\", \"lon_k\", \"date_k\"]\n",
    "\n",
    "train_df = wq_train.merge(tc_train.drop(columns=[\"Latitude\",\"Longitude\",\"Sample Date\"], errors=\"ignore\"),\n",
    "                          on=merge_keys, how=\"left\", suffixes=(\"\", \"_tc\"))\n",
    "train_df = train_df.merge(ls_train.drop(columns=[\"Latitude\",\"Longitude\",\"Sample Date\"], errors=\"ignore\"),\n",
    "                          on=merge_keys, how=\"left\", suffixes=(\"\", \"_ls\"))\n",
    "\n",
    "print(\"train_df shape:\", train_df.shape)\n",
    "print(\"train_df columns (head):\", list(train_df.columns)[:30])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28bf52b-09ba-4ed5-a566-2b651ec47bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files:\n",
      "WQ: water_quality_training_dataset.csv\n",
      "TC: terraclimate_features_training.csv\n",
      "LS: landsat_features_training.csv\n",
      "Merged train_df shape: (19278121, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "      <th>lat_k</th>\n",
       "      <th>lon_k</th>\n",
       "      <th>date_k</th>\n",
       "      <th>Latitude_tc</th>\n",
       "      <th>...</th>\n",
       "      <th>pet</th>\n",
       "      <th>Latitude_ls</th>\n",
       "      <th>Longitude_ls</th>\n",
       "      <th>Sample Date_ls</th>\n",
       "      <th>nir</th>\n",
       "      <th>green</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>128.912</td>\n",
       "      <td>555.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-28.76083</td>\n",
       "      <td>17.73028</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>-28.760833</td>\n",
       "      <td>...</td>\n",
       "      <td>174.2</td>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11190.0</td>\n",
       "      <td>11426.0</td>\n",
       "      <td>7687.5</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>0.185538</td>\n",
       "      <td>0.195595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>74.720</td>\n",
       "      <td>162.9</td>\n",
       "      <td>163.0</td>\n",
       "      <td>-26.86111</td>\n",
       "      <td>28.88472</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>-26.861111</td>\n",
       "      <td>...</td>\n",
       "      <td>124.1</td>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>17658.5</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>13746.5</td>\n",
       "      <td>10574.0</td>\n",
       "      <td>0.124566</td>\n",
       "      <td>-0.180134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>89.254</td>\n",
       "      <td>573.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-26.45000</td>\n",
       "      <td>28.08583</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>-26.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>127.5</td>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>15210.0</td>\n",
       "      <td>10720.0</td>\n",
       "      <td>17974.0</td>\n",
       "      <td>14201.0</td>\n",
       "      <td>-0.083293</td>\n",
       "      <td>-0.252805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>82.000</td>\n",
       "      <td>203.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-27.67111</td>\n",
       "      <td>27.23694</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>-27.671111</td>\n",
       "      <td>...</td>\n",
       "      <td>129.7</td>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>14887.0</td>\n",
       "      <td>10943.0</td>\n",
       "      <td>13522.0</td>\n",
       "      <td>11403.0</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>-0.105416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>56.100</td>\n",
       "      <td>145.1</td>\n",
       "      <td>151.0</td>\n",
       "      <td>-27.35667</td>\n",
       "      <td>27.28639</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>-27.356667</td>\n",
       "      <td>...</td>\n",
       "      <td>129.2</td>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>16828.5</td>\n",
       "      <td>9502.5</td>\n",
       "      <td>12665.5</td>\n",
       "      <td>9643.0</td>\n",
       "      <td>0.141147</td>\n",
       "      <td>-0.142683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0 -28.760833  17.730278  2011-02-01           128.912                   555.0   \n",
       "1 -26.861111  28.884722  2011-03-01            74.720                   162.9   \n",
       "2 -26.450000  28.085833  2011-03-01            89.254                   573.0   \n",
       "3 -27.671111  27.236944  2011-03-01            82.000                   203.6   \n",
       "4 -27.356667  27.286389  2011-03-01            56.100                   145.1   \n",
       "\n",
       "   Dissolved Reactive Phosphorus     lat_k     lon_k      date_k  Latitude_tc  \\\n",
       "0                           10.0 -28.76083  17.73028  2011-02-01   -28.760833   \n",
       "1                          163.0 -26.86111  28.88472  2011-03-01   -26.861111   \n",
       "2                           80.0 -26.45000  28.08583  2011-03-01   -26.450000   \n",
       "3                          101.0 -27.67111  27.23694  2011-03-01   -27.671111   \n",
       "4                          151.0 -27.35667  27.28639  2011-03-01   -27.356667   \n",
       "\n",
       "   ...    pet Latitude_ls  Longitude_ls  Sample Date_ls      nir    green  \\\n",
       "0  ...  174.2  -28.760833     17.730278      2011-02-01  11190.0  11426.0   \n",
       "1  ...  124.1  -26.861111     28.884722      2011-03-01  17658.5   9550.0   \n",
       "2  ...  127.5  -26.450000     28.085833      2011-03-01  15210.0  10720.0   \n",
       "3  ...  129.7  -27.671111     27.236944      2011-03-01  14887.0  10943.0   \n",
       "4  ...  129.2  -27.356667     27.286389      2011-03-01  16828.5   9502.5   \n",
       "\n",
       "    swir16   swir22      NDMI     MNDWI  \n",
       "0   7687.5   7645.0  0.185538  0.195595  \n",
       "1  13746.5  10574.0  0.124566 -0.180134  \n",
       "2  17974.0  14201.0 -0.083293 -0.252805  \n",
       "3  13522.0  11403.0  0.048048 -0.105416  \n",
       "4  12665.5   9643.0  0.141147 -0.142683  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\".\")  # change if needed, e.g. Path(\"/path/to/Models/BaseData\")\n",
    "\n",
    "# ---- auto-find files (so you don't get FileNotFoundError) ----\n",
    "def find_one(patterns):\n",
    "    for pat in patterns:\n",
    "        hits = list(BASE_DIR.glob(pat))\n",
    "        if hits:\n",
    "            return hits[0]\n",
    "    raise FileNotFoundError(f\"Could not find file for patterns: {patterns} in {BASE_DIR.resolve()}\")\n",
    "\n",
    "WQ_TRAIN_PATH = find_one([\"*water_quality*training*.csv\", \"*water_quality_training_dataset*.csv\"])\n",
    "TC_TRAIN_PATH = find_one([\"*terraclimate*training*.csv\", \"*terraclimate_features_training*.csv\"])\n",
    "LS_TRAIN_PATH = find_one([\"*landsat*training*.csv\", \"*landsat_features_training*.csv\"])\n",
    "\n",
    "print(\"Training files:\")\n",
    "print(\"WQ:\", WQ_TRAIN_PATH.name)\n",
    "print(\"TC:\", TC_TRAIN_PATH.name)\n",
    "print(\"LS:\", LS_TRAIN_PATH.name)\n",
    "\n",
    "# ---- key prep (robust merge keys) ----\n",
    "def _clean_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def _prepare_keys(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = _clean_cols(df)\n",
    "    # standard expected columns\n",
    "    if \"Sample Date\" in df.columns:\n",
    "        df[\"Sample Date\"] = pd.to_datetime(df[\"Sample Date\"], errors=\"coerce\")\n",
    "    # numeric safety\n",
    "    if \"Latitude\" in df.columns:\n",
    "        df[\"Latitude\"] = pd.to_numeric(df[\"Latitude\"], errors=\"coerce\")\n",
    "    if \"Longitude\" in df.columns:\n",
    "        df[\"Longitude\"] = pd.to_numeric(df[\"Longitude\"], errors=\"coerce\")\n",
    "\n",
    "    # stable merge keys (rounding helps when joins fail due to float precision)\n",
    "    df[\"lat_k\"] = df[\"Latitude\"].round(5)\n",
    "    df[\"lon_k\"] = df[\"Longitude\"].round(5)\n",
    "    df[\"date_k\"] = df[\"Sample Date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    return df\n",
    "\n",
    "merge_keys = [\"lat_k\", \"lon_k\", \"date_k\"]\n",
    "\n",
    "# ---- load ----\n",
    "wq_train = _prepare_keys(pd.read_csv(WQ_TRAIN_PATH))\n",
    "tc_train = _prepare_keys(pd.read_csv(TC_TRAIN_PATH))\n",
    "ls_train = _prepare_keys(pd.read_csv(LS_TRAIN_PATH))\n",
    "\n",
    "# ---- merge ----\n",
    "train_df = wq_train.merge(tc_train, on=merge_keys, how=\"left\", suffixes=(\"\", \"_tc\"))\n",
    "train_df = train_df.merge(ls_train, on=merge_keys, how=\"left\", suffixes=(\"\", \"_ls\"))\n",
    "\n",
    "print(\"Merged train_df shape:\", train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f14134-6140-4975-a988-16d5e1a3eb6a",
   "metadata": {},
   "source": [
    "# (2) Train XGBoost “epoch-like” (boosting rounds), multi-run, tunable, with early stopping\n",
    "\n",
    "- This cell:\n",
    "- adds safe engineered features (time + coarse spatial bins)\n",
    "- defines XGBoost params you can tune\n",
    "- trains one model per target\n",
    "- repeats training for multiple seeds (runs) and stores learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548070ed-7b9a-4e41-a89e-a7e15c6cd0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost version: 3.1.3\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(\"xgboost version:\", xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e202a80f-676c-4c52-9026-6af14bdbeef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert NA to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth_cos\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m*\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m12.0\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 24\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43madd_time_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# ---- pick numeric features only (XGBoost needs numeric) ----\u001b[39;00m\n\u001b[1;32m     27\u001b[0m drop_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(TARGETS \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample Date\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat_k\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon_k\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_k\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36madd_time_features\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     16\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n\u001b[1;32m     17\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdayofyear\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdayofyear\n\u001b[0;32m---> 18\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweekofyear\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misocalendar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweek\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# cyclic month\u001b[39;00m\n\u001b[1;32m     20\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth_sin\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msin(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m*\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m12.0\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/tf310/lib/python3.10/site-packages/pandas/core/generic.py:6662\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6656\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6657\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6658\u001b[0m     ]\n\u001b[1;32m   6660\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6661\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6662\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6663\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/tf310/lib/python3.10/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/tf310/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.pyenv/versions/tf310/lib/python3.10/site-packages/pandas/core/internals/blocks.py:784\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    782\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 784\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    788\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/tf310/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/tf310/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:179\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/.pyenv/versions/tf310/lib/python3.10/site-packages/pandas/core/arrays/masked.py:587\u001b[0m, in \u001b[0;36mBaseMaskedArray.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# to_numpy will also raise, but we get somewhat nicer exception messages here\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hasna:\n\u001b[0;32m--> 587\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert NA to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hasna:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;66;03m# careful: astype_nansafe converts np.nan to True\u001b[39;00m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert float NaN to bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert NA to integer"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TARGETS = [\"Total Alkalinity\", \"Electrical Conductance\", \"Dissolved Reactive Phosphorus\"]\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    dt = pd.to_datetime(df[\"Sample Date\"], errors=\"coerce\")\n",
    "    df[\"year\"] = dt.dt.year\n",
    "    df[\"month\"] = dt.dt.month\n",
    "    df[\"dayofyear\"] = dt.dt.dayofyear\n",
    "    df[\"weekofyear\"] = dt.dt.isocalendar().week.astype(\"int64\")\n",
    "    # cyclic month\n",
    "    df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12.0)\n",
    "    df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12.0)\n",
    "    return df\n",
    "\n",
    "train_df = add_time_features(train_df)\n",
    "\n",
    "drop_cols = set(TARGETS + [\"Sample Date\", \"Latitude\", \"Longitude\", \"lat_k\", \"lon_k\", \"date_k\"])\n",
    "numeric_features = []\n",
    "for c in train_df.columns:\n",
    "    if c in drop_cols:\n",
    "        continue\n",
    "    if pd.api.types.is_numeric_dtype(train_df[c]):\n",
    "        numeric_features.append(c)\n",
    "\n",
    "FEATURES = numeric_features\n",
    "print(\"Num FEATURES:\", len(FEATURES))\n",
    "\n",
    "df_non_null = train_df.dropna(subset=TARGETS).copy()\n",
    "\n",
    "train_idx, valid_idx = train_test_split(\n",
    "    df_non_null.index,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_part = df_non_null.loc[train_idx].copy()\n",
    "valid_part = df_non_null.loc[valid_idx].copy()\n",
    "\n",
    "xgb_params = dict(\n",
    "    n_estimators=8000,          \n",
    "    learning_rate=0.02,\n",
    "    max_depth=6,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=6.0,\n",
    "    min_child_weight=3,\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",        \n",
    "    eval_metric=\"rmse\",\n",
    "    early_stopping_rounds=250,\n",
    ")\n",
    "\n",
    "SEEDS = [42, 99, 202, 777]     \n",
    "\n",
    "models_by_target = {t: [] for t in TARGETS}\n",
    "hist_by_target   = {t: [] for t in TARGETS}\n",
    "scores_by_target = {t: [] for t in TARGETS}\n",
    "\n",
    "for seed in SEEDS:\n",
    "    for tgt in TARGETS:\n",
    "        X_tr = train_part[FEATURES]\n",
    "        y_tr = train_part[tgt].values\n",
    "        X_va = valid_part[FEATURES]\n",
    "        y_va = valid_part[tgt].values\n",
    "\n",
    "        model = XGBRegressor(**xgb_params, random_state=seed)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_tr, y_tr), (X_va, y_va)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        pred_tr = model.predict(X_tr)\n",
    "        pred_va = model.predict(X_va)\n",
    "\n",
    "        models_by_target[tgt].append(model)\n",
    "        hist_by_target[tgt].append(model.evals_result())\n",
    "        scores_by_target[tgt].append({\n",
    "            \"seed\": seed,\n",
    "            \"best_iteration\": int(model.best_iteration) if model.best_iteration is not None else None,\n",
    "            \"train_r2\": r2_score(y_tr, pred_tr),\n",
    "            \"train_rmse\": rmse(y_tr, pred_tr),\n",
    "            \"valid_r2\": r2_score(y_va, pred_va),\n",
    "            \"valid_rmse\": rmse(y_va, pred_va),\n",
    "        })\n",
    "\n",
    "print(\"Done training multiple runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44880cae-d3dd-4148-b043-d346dc1ce7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (TF)",
   "language": "python",
   "name": "tf310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
